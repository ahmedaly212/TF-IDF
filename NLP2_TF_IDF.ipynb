{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0B1hbyDPS7Z",
        "outputId": "736e079a-f6d4-4c03-e58e-8cdc929bdf5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text for prompt 'machine learning':\n",
            "[{'generated_text': \"machine learning in general â€” which is one of the major new areas that we will be talking about today. It's not new.\\n\\nI'm surprised this issue hasn't been up for discussion in a lot of places. It's certainly not new\"}]\n",
            "\n",
            "Generated text for prompt 'computer science':\n",
            "[{'generated_text': 'computer science with data analysis will allow you to use the data in your analysis using various tools for creating real-time forecasts.\\n\\nA model like Hadoop can take any dataset and combine them to produce a \"skeleton,\" with each dimension'}]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "# Initialize the text generation pipeline with the desired model\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Generate text for the prompts\n",
        "prompt1 = \"machine learning\"\n",
        "generated_text1 = generator(prompt1, max_length=50)\n",
        "\n",
        "prompt2 = \"computer science\"\n",
        "generated_text2 = generator(prompt2, max_length=50)\n",
        "\n",
        "print(\"Generated text for prompt 'machine learning':\")\n",
        "print(generated_text1)\n",
        "\n",
        "print(\"\\nGenerated text for prompt 'computer science':\")\n",
        "print(generated_text2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing function\n",
        "def preprocess_document(document):\n",
        "    document = document.lower()\n",
        "    document = re.sub(r'[^a-zA-Z\\s]', ' ', document)\n",
        "    tokens = word_tokenize(document)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stopwords.words('english')]\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return ' '.join(filtered_tokens)"
      ],
      "metadata": {
        "id": "SVSak6BsQCdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTFIDF:\n",
        "    def __init__(self):\n",
        "        self.idf_ = {}\n",
        "        self.vocab_ = {}\n",
        "\n",
        "    def fit_transform(self, documents):\n",
        "        tf = []\n",
        "        doc_count = len(documents)\n",
        "\n",
        "        # Compute term frequencies and document frequencies for IDF\n",
        "        for document in documents:\n",
        "            doc_tf = {}\n",
        "            words = document.split()\n",
        "            for word in words:\n",
        "                doc_tf[word] = doc_tf.get(word, 0) + 1\n",
        "            for word in doc_tf:\n",
        "                doc_tf[word] = doc_tf[word] / len(words)\n",
        "                self.idf_[word] = self.idf_.get(word, 0) + 1\n",
        "            tf.append(doc_tf)\n",
        "\n",
        "        # Sort the vocabulary alphabetically and assign indices\n",
        "        sorted_vocab = sorted(self.idf_.keys())\n",
        "        self.vocab_ = {word: idx for idx, word in enumerate(sorted_vocab)}\n",
        "\n",
        "        # Compute IDF using the sorted vocabulary\n",
        "        for word in self.idf_:\n",
        "            self.idf_[word] = np.log((1 + doc_count) / (1 + self.idf_[word])) + 1\n",
        "\n",
        "        # Compute TF-IDF scores using the sorted vocabulary\n",
        "        tfidf = []\n",
        "        for doc in tf:\n",
        "            doc_tfidf = np.zeros(len(self.vocab_))\n",
        "            for word, value in doc.items():\n",
        "                if word in self.vocab_:\n",
        "                    index = self.vocab_[word]\n",
        "                    doc_tfidf[index] = value * self.idf_[word]\n",
        "            # Normalization\n",
        "            norm = np.linalg.norm(doc_tfidf)\n",
        "            if norm > 0:\n",
        "                doc_tfidf = doc_tfidf / norm\n",
        "            tfidf.append(doc_tfidf)\n",
        "\n",
        "        return np.array(tfidf)"
      ],
      "metadata": {
        "id": "msb1pjMNPEV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract generated texts\n",
        "generated_text_prompt1 = generated_text1[0]['generated_text']\n",
        "generated_text_prompt2 = generated_text2[0]['generated_text']\n",
        "\n",
        "# Incorporating generated texts into documents along with prompts\n",
        "documents = [prompt1, generated_text_prompt1, prompt2, generated_text_prompt2]\n",
        "\n",
        "# Preprocess documents\n",
        "preprocessed_docs = [preprocess_document(doc) for doc in documents]\n",
        "\n",
        "# Using CustomTFIDF\n",
        "custom_tfidf = CustomTFIDF()\n",
        "custom_tfidf_matrix = custom_tfidf.fit_transform(preprocessed_docs)\n",
        "\n",
        "# Using sklearn for comparison\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "sklearn_tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_docs).toarray()"
      ],
      "metadata": {
        "id": "5uOLbdd7PCC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkSn2sZgPS7e",
        "outputId": "4983ef17-13b8-43dd-df4c-d70f18a32416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom TF-IDF vs. sklearn TF-IDF:\n",
            "Custom: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.70710678 0.         0.\n",
            "  0.70710678 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.21203205 0.21203205 0.         0.\n",
            "  0.         0.         0.         0.         0.21203205 0.\n",
            "  0.21203205 0.         0.21203205 0.1671685  0.         0.21203205\n",
            "  0.1671685  0.21203205 0.         0.63609615 0.21203205 0.21203205\n",
            "  0.         0.         0.         0.         0.21203205 0.\n",
            "  0.21203205 0.         0.21203205 0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.70710678\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70710678 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.19158921 0.38317843 0.         0.         0.19158921 0.15105114\n",
            "  0.19158921 0.38317843 0.19158921 0.19158921 0.         0.19158921\n",
            "  0.         0.19158921 0.         0.         0.19158921 0.\n",
            "  0.         0.         0.19158921 0.         0.         0.\n",
            "  0.19158921 0.19158921 0.15105114 0.19158921 0.         0.19158921\n",
            "  0.         0.19158921 0.         0.19158921 0.19158921 0.19158921\n",
            "  0.19158921]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Custom TF-IDF vs. sklearn TF-IDF:\")\n",
        "print(\"Custom:\", custom_tfidf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drEnT7SSPS7f",
        "outputId": "287f3f28-312f-43d3-ee48-4ccb7bd143cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom TF-IDF vs. sklearn TF-IDF:\n",
            "sklearn: [[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.70710678 0.         0.\n",
            "  0.70710678 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.21203205 0.21203205 0.         0.\n",
            "  0.         0.         0.         0.         0.21203205 0.\n",
            "  0.21203205 0.         0.21203205 0.1671685  0.         0.21203205\n",
            "  0.1671685  0.21203205 0.         0.63609615 0.21203205 0.21203205\n",
            "  0.         0.         0.         0.         0.21203205 0.\n",
            "  0.21203205 0.         0.21203205 0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.70710678\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.70710678 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.19158921 0.38317843 0.         0.         0.19158921 0.15105114\n",
            "  0.19158921 0.38317843 0.19158921 0.19158921 0.         0.19158921\n",
            "  0.         0.19158921 0.         0.         0.19158921 0.\n",
            "  0.         0.         0.19158921 0.         0.         0.\n",
            "  0.19158921 0.19158921 0.15105114 0.19158921 0.         0.19158921\n",
            "  0.         0.19158921 0.         0.19158921 0.19158921 0.19158921\n",
            "  0.19158921]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Custom TF-IDF vs. sklearn TF-IDF:\")\n",
        "print(\"sklearn:\", sklearn_tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9SZjuQu1Z14L"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}